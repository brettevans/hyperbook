# Chapter 11: Integration testing

## Comparing integration test options

If you find yourself struggling with excessive mocking and hard to maintain tests consider integration testing your application. 
Some JS developers find their **integration tests** give them more leverage than unit tests.
Therefore they subvert a traditional [test pyramid](https://martinfowler.com/bliki/TestPyramid.html) and write more integration tests than unit tests.

One popular option for integration testing your app is DOM emulation with ```jsdom``` and polyfills/test doubles for various API such as 
```fetch```, ```localStorage``` or ```EventSource```.
This approach allows to write Node.js tests for your frontend code without spinning a browser. 
Personally, I've spent too much time trying to match browser environment in this setup and I'm not sure if it's worth the effort. 
Your mileage may vary though. Also, with ```jsdom``` you're not integration testing against a real browser. 

```jsdom``` based setup tradeoffs:
* (+) easy to run from CLI without extra tooling
* (+) faster tests in CI server than spinning-up browser tests
* (-) slow startup time for the first test which makes subsecond testing impossible
* (-) can't find browser discrepancies

Another option is to run your tests in a real browser.
With this approach all APIs just work and you can inspect a failing tests with your DevTools. 

Browser based setup tradeoffs:
* (+) testing a real browser
* (+) easy to inspect the environment after a failing tests
* (+) all APIs just work
* (+) with an open browser first test starts instantly  
* (-) cleaning the environment between tests is cumbersome
* (-) requires complex tooling to run in the CI server
* (-) with many tests it's slower than ```jsdom``` because of the rendering overhead

## Testing in a browser

```mocha``` tests run in both Node.js and in different browsers. Not all test runners have this capability. 

Create **test/index.html** with the following boilerplate:
```html
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8" />
    <title>Mocha Tests</title>
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <link rel="stylesheet" href="https://unpkg.com/mocha/mocha.css" />
</head>
<body>
<div id="mocha">
    <div id="app"></div>
</div>

<script src="https://unpkg.com/mocha@7.1.2/mocha.js"></script>
<script src="https://unpkg.com/chai@4.2.0/chai.js"></script>
<script src="https://unpkg.com/browse/@testing-library/dom@7.5.6/dist/@testing-library/dom.umd.js"></script>

<script class="mocha-init">
    mocha.setup('bdd');
</script>
<script type="module" src="App.test.js"></script>
<script type="module" class="mocha-exec">
    mocha.run();
</script>
</body>
</html>
```
This setup loads 3 scripts.
* ```mocha``` - browser based test runner
* ```chai``` - assertion library. Browsers don't provide built-in assertion libraries similar to Node ```assert```
* ```@testing-library/dom``` - a helpful utility library you'll use for asynchronous rendering testing  

We load the scripts from unpkg.com. In real world setup you'd rather load them locally. Also, all scripts other than
```mocha``` could be loaded as ESM imports.

You app will mount to ```<div id="app"></div>```.

Write a test in **test/App.test.js**:
```javascript
const { assert } = chai;
const { getAllByTestId, waitFor } = TestingLibraryDom;
import { start } from "../src/App.js";

const container = () => document.getElementById("app");

describe("App", () => {
  beforeEach(function () {
    container().innerHTML = "";
  });

  it("Load initial posts", async () => {
    start();
    await waitFor(() => {
      assert.strictEqual(getAllByTestId(container(), "item").length, 10);
    });
  });
});

```
The code cleans up the app container before every test. It's important to start each test with a clean slate.
Always prefer ```beforeEach``` over ```afterEach``` for cleanup as you may need to inspect a failing test every now and then.
```afterEach``` would erase useful debugging information.

Inside a test, start a new instance of the app. Then wait for the 10 items to show up. 
```getAllByTestId``` is a utility querying for ```data-testid="item```. 
```waitFor``` runs until:
* the assertion doesn't throw any errors
* waitFor times out 
* mocha times out

Change **src/App.js**:
```javascript
import { app } from "./web_modules/hyperapp.js";
import { init, view, subscriptions } from "./Posts.js";

export const start = () =>
  app({
    init,
    view,
    subscriptions,
    node: document.getElementById("app"),
  });
```
It defers app intialization so that it can be started anew in each test.

Add **src/Start.js**:
```javascript
import { start } from "./App.js";

start();
```
Refer to this file from **src/index.html**:
```html
<script type="module" src="Start.js"></script>
```

Add the test data attribute to the ```listItem``` view fragment in **src/Posts.js**:
```javascript
const listItem = (post) => html`
  <li key=${post.id} data-key=${post.id} data-testid="item">
    ...
  </li>
`;
```

Start a server from the root directory: ```http-server .```

Open http://localhost:8080/test/ in your browser. The test should be green.

![Figure: Mocha browser test output](images/mocha-browser.png)

## Testing more advanced browser scenario

Add a test for the post submission and waiting for the SSE notification:
```javascript
const {
  getAllByTestId,
  waitFor,
  findByTestId,
  findByText,
  fireEvent,
} = TestingLibraryDom;

  const randomMessage = () => `new message ${new Date().toJSON()}`;

  const sendMessage = async (newMessage) => {
    const input = await findByTestId(container(), "post-input");
    input.value = newMessage;
    fireEvent.input(input);

    const button = await findByText(container(), "Add Post");
    button.click();
  };

  const waitForMessage = async (message) => {
    await waitFor(() => {
      assert.strictEqual(
        getAllByTestId(container(), "item")[0].textContent,
        message
      );
    });
  };

  it("Add a post as anonymous user", async () => {
    start();
    const newMessage = randomMessage();

    await sendMessage(newMessage);

    await waitForMessage(`@anonymous ${newMessage}`);
  });
```
The test starts a new app to make it independent of the other tests. 
TODO: One thing I'm missing in Hyperapp is the ability to stop all subscriptions from the previous test. 

With the app started:
* create a random message
* send the message to the server - ```@testing-library``` simplifies firing DOM events such as typing a text. It also provides DOM queries
that wait for DOM elements to appear in the UI.
* wait for the message to show up at the top of the post list 

Put a test data attribute in **Posts.js**:
```javascript
    <input
      data-testid="post-input"
      type="text"
      oninput=${[UpdatePostText, targetValue]}
      value=${state.currentPostText}
      autofocus
    />
```

Check if both tests are green.

## Making integration tests faster and more predictable

You integration test execution time and reliability are heavily dependent on the API response time and availability. 
There are at least two options to make your tests faster and more reliable:
* record all HTTP traffic with a library like [PollyJS](https://netflix.github.io/pollyjs/#/). 
The first time you run the tests it intercepts all network calls and saves them to localStorage/REST API etc. 
Afterwards it can replay the traffic much faster than the original API. When the API changes you make a new recording.
* inject fake implementation of all effects and subscriptions you want to replace. 
The trick is to move all effects and subscriptions to the entry point of your application.
In production you can start your app with real effects/subscriptions:
```javascript
import { start } from "./App.js";
import { Http } from "./web_modules/hyperapp-fx.js";
import { EventSourceListen } from "./lib/EventSource.js";
import { WithGuid } from "./lib/Guid.js";

start({Http, EventSourceListen, WithGuid});
```
In your tests your can provide fake implementation of those effects/subscriptions. 
This technique requires minor code changes. Each module with effects needs to expose a function for injecting those.
This is essentially what some people call a dependency injection. A fancy name for passing arguments to functions.
 
I leave it to the reader to experiment with those techniques.